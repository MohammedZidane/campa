{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from campa.constants import EXPERIMENT_DIR, get_data_config\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "\n",
    "EXPERIMENT_DIR = \"/Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments\"\n",
    "\n",
    "def prepare_test_experiment(name, cluster_subset=False, full_data_prediction=False, full_data_clustering=False):\n",
    "    \"\"\"\n",
    "    Copy reference_experiment with the specified components to name\n",
    "    \"\"\"\n",
    "    from_dir = Path(EXPERIMENT_DIR)/\"reference_experiment/cVAE\"\n",
    "    to_dir = Path(EXPERIMENT_DIR)/\"test_experiment\"/name\n",
    "    # delete to_dir if it exists\n",
    "    if to_dir.exists():\n",
    "        shutil.rmtree(to_dir)\n",
    "    to_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # copy model\n",
    "    files_to_copy = []\n",
    "    dirs_to_copy = []\n",
    "    # copy model\n",
    "    files_to_copy.extend([\"checkpoint\", \"config.json\", \"history.csv\", \n",
    "        \"weights_epoch005.data-00000-of-00001\", 'weights_epoch005.index'])\n",
    "    dirs_to_copy.append('results_epoch005')\n",
    "    if cluster_subset:\n",
    "        dirs_to_copy.extend([\"aggregated/sub-0.1\"])\n",
    "    if full_data_prediction:\n",
    "        full_data_base = Path(\"aggregated/full_data\")\n",
    "        full_data_files = ['channels.csv', 'latent.npy', 'metadata.csv', 'mpp_params.json', 'obj_ids.npy', 'x.npy', 'y.npy']\n",
    "        for data_dir in [\"184A1_unperturbed/I09\", \"184A1_meayamycin/I12\"]:\n",
    "            files_to_copy.extend([full_data_base/data_dir/f for f in full_data_files])\n",
    "    if full_data_clustering:\n",
    "        full_data_base = Path(\"aggregated/full_data\")\n",
    "        full_data_files = ['clustering.npy']\n",
    "        for data_dir in [\"184A1_unperturbed/I09\", \"184A1_meayamycin/I12\"]:\n",
    "            files_to_copy.extend([full_data_base/data_dir/f for f in full_data_files])\n",
    "    \n",
    "    # ensure dirs exist \n",
    "    for data_dir in [\"184A1_unperturbed/I09\", \"184A1_meayamycin/I12\"]:\n",
    "        (to_dir/\"aggregated/full_data\"/data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    # copy files\n",
    "    for f in files_to_copy:\n",
    "        shutil.copy(from_dir/f, to_dir/f)\n",
    "    # copy dirs\n",
    "    for f in dirs_to_copy:\n",
    "        shutil.copytree(from_dir/f, to_dir/f)\n",
    "\n",
    "    # correct experiment dir + name in config.json\n",
    "    config = json.load(open(to_dir/\"config.json\", 'r'))\n",
    "    config['experiment']['dir'] = \"test_experiment\"\n",
    "    config['experiment']['name'] = name\n",
    "    json.dump(config, open(to_dir/\"config.json\", 'w'), indent=4)\n",
    "\n",
    "prepare_test_experiment(\"exp1\", cluster_subset=True, full_data_prediction=True, full_data_clustering=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config from /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/campa.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah.spitzer/opt/miniconda3/envs/campa/lib/python3.9/site-packages/docrep/decorators.py:43: SyntaxWarning: 'plotting' is not a valid key!\n",
      "  doc = func(self, args[0].__doc__, *args[1:], **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from campa.tl import Experiment, run_experiments\n",
    "from campa.data import create_dataset\n",
    "from campa.tl import project_cluster_data, create_cluster_data, prepare_full_dataset, extract_features\n",
    "from campa.data import NNDataset\n",
    "\n",
    "def create_nn_dataset():\n",
    "    # create test_dataset\n",
    "    data_params = {\n",
    "        'dataset_name': 'test_dataset',\n",
    "        'data_config': \"TestData\",\n",
    "        'data_dirs': \n",
    "                [os.path.join('184A1_unperturbed', well) for well in ['I09',]] + \\\n",
    "                [os.path.join('184A1_meayamycin', well) for well in ['I12',]],\n",
    "        'channels': ['01_PABPC1', '03_CDK9', '09_SRRM2', '10_POL2RA_pS2', '11_PML',], \n",
    "        'condition': ['perturbation_duration_one_hot', 'cell_cycle_one_hot'],\n",
    "        'condition_kwargs': {\n",
    "            'cond_params': {}\n",
    "        },\n",
    "        'split_kwargs': {\n",
    "            'train_frac': 0.35,\n",
    "            'val_frac': 0.35,\n",
    "        },\n",
    "        'test_img_size': 225,\n",
    "        'subset': True,\n",
    "        'subset_kwargs': {\n",
    "            'frac': None,\n",
    "            'nona_condition': True,\n",
    "            'cell_cycle': 'NO_NAN'\n",
    "        },\n",
    "        'subsample': True,\n",
    "        'subsample_kwargs': {\n",
    "            'frac': None,\n",
    "            'frac_per_obj': None,\n",
    "            'num': None,\n",
    "            'num_per_obj': 100,\n",
    "        },\n",
    "        'neighborhood': True,\n",
    "        'neighborhood_size': 3,\n",
    "        'normalise': True,\n",
    "        'normalise_kwargs': {\n",
    "            'background_value': 'mean_background',\n",
    "            'percentile': 98.0,\n",
    "            'rescale_values': [],\n",
    "        },\n",
    "        'seed': 42,\n",
    "    }\n",
    "    create_dataset(data_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn_dataset():\n",
    "    create_nn_dataset()\n",
    "    test_ds = NNDataset(\"test_dataset\", data_config='TestData')\n",
    "    reference_ds = NNDataset(\"reference_dataset\", data_config='TestData')\n",
    "\n",
    "    # compare test and reference ds\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        assert test_ds.data[split].compare(reference_ds.data[split])[0]\n",
    "    for split in ['val', 'test']:\n",
    "        assert test_ds.imgs[split].compare(reference_ds.imgs[split])[0]\n",
    "\n",
    "test_nn_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from campa.tl import Estimator, Cluster\n",
    "import random\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "def train_model(model_name):\n",
    "    from campa.tl import LossEnum, ModelEnum\n",
    "    experiment_config = {\n",
    "        \"experiment\": {\n",
    "            \"dir\": \"test_experiment\",\n",
    "            \"name\": model_name,\n",
    "            \"save_config\": True,\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"data_config\": \"TestData\",\n",
    "            \"dataset_name\": \"reference_dataset\",\n",
    "            \"output_channels\": None,\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"model_cls\":  ModelEnum.VAEModel,\n",
    "            \"model_kwargs\": {\n",
    "                \"num_neighbors\": 3,\n",
    "                \"num_channels\": 5,\n",
    "                \"num_output_channels\": 5,\n",
    "                \"latent_dim\": 4,\n",
    "                # encoder definition\n",
    "                \"encoder_conv_layers\": [16],\n",
    "                \"encoder_conv_kernel_size\": [1],\n",
    "                \"encoder_fc_layers\": [8],\n",
    "                # decoder definition\n",
    "                \"decoder_fc_layers\": [],\n",
    "                \"num_conditions\": 6,\n",
    "                \"encode_condition\": [6],\n",
    "            },\n",
    "            # if true, looks for saved weights in experiment_dir\n",
    "            # if a path, loads these weights\n",
    "            \"init_with_weights\": False,\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"epochs\": 5,\n",
    "            \"batch_size\": 128,\n",
    "            \"loss\": {\"decoder\": LossEnum.SIGMA_MSE, \"latent\": LossEnum.KL},\n",
    "            \"metrics\": {\"decoder\": LossEnum.MSE_metric, \"latent\": LossEnum.KL},\n",
    "            # saving models\n",
    "            \"save_model_weights\": True,\n",
    "            \"save_history\": True,\n",
    "            \"overwrite_history\": True,\n",
    "        },\n",
    "        \"evaluation\": {\n",
    "            \"split\": \"val\",\n",
    "            \"predict_reps\": [\"latent\", \"decoder\"],\n",
    "            \"img_ids\": 1,\n",
    "            \"predict_imgs\": True,\n",
    "            \"predict_cluster_imgs\": True,\n",
    "        },\n",
    "        \"cluster\": {  # cluster config, also used in this format for whole data clustering\n",
    "            \"cluster_name\": \"clustering\",\n",
    "            \"cluster_rep\": \"latent\",\n",
    "            \"cluster_method\": \"leiden\",  # leiden or kmeans\n",
    "            \"leiden_resolution\": 0.2,\n",
    "            \"subsample\": True,  # 'subsample' or 'som'\n",
    "            \"subsample_kwargs\": {'frac': 0.1},\n",
    "            \"som_kwargs\": {},\n",
    "            \"umap\": True,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    exp = Experiment(experiment_config)\n",
    "    run_experiments([exp], mode='trainval')\n",
    "\n",
    "def test_model_training():\n",
    "    model_name = id_generator(size=6)\n",
    "    #model_name = \"SASY21\"\n",
    "    train_model(model_name)\n",
    "\n",
    "    # check if all expected files are created\n",
    "    exp = Experiment.from_dir(\"test_experiment/\"+model_name)\n",
    "    exp.set_to_evaluate()\n",
    "    _ = Estimator(exp)\n",
    "    \n",
    "\n",
    "test_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load MPPData from test_experiment/8SXVWJ/aggregated/sub-0.1\n",
      "Could not load MPPData from test_experiment/8SXVWJ/aggregated/sub-0.1\n",
      "Saving partial keys of mpp data without a base_data_dir to enable correct loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah.spitzer/opt/miniconda3/envs/campa/lib/python3.9/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "Saving partial keys of mpp data without a base_data_dir to enable correct loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot read with memmap:  /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments/test_experiment/8SXVWJ/aggregated/sub-0.1/clustering.npy\n",
      "Cannot read with memmap:  /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments/reference_experiment/cVAE/aggregated/sub-0.1/clustering.npy\n",
      "[[ 0.7025145   1.0100106   0.3618012  -0.54160935]\n",
      " [ 3.0500026   0.01753122  0.05046673 -1.4755267 ]\n",
      " [-0.24107969 -1.0978781  -0.4569826   0.30672166]\n",
      " ...\n",
      " [ 0.2739511  -0.49121684  0.92969525 -1.496013  ]\n",
      " [ 1.2105104  -0.59349877 -1.1900173   0.52722204]\n",
      " [ 0.3490503  -1.6331238   2.2730925  -0.9045105 ]]\n",
      "[[ 0.5271177   0.1882852  -1.0454091  -0.5767247 ]\n",
      " [ 1.8563808  -1.482907   -1.2025827   0.43522835]\n",
      " [ 0.89105386  0.32178292 -0.39630467  1.3699696 ]\n",
      " ...\n",
      " [ 0.5740625  -0.50714755 -0.652853    0.30780938]\n",
      " [ 0.46897215  0.5794399  -0.2598577   0.9203548 ]\n",
      " [ 0.12242371 -0.5240741  -0.42662796 -0.7542753 ]]\n",
      "[[False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " ...\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah.spitzer/opt/miniconda3/envs/campa/lib/python3.9/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "from campa.tl import Cluster\n",
    "def cluster(model_name):\n",
    "    prepare_test_experiment(model_name, cluster_subset=False, full_data_prediction=False, full_data_clustering=False)\n",
    "    create_cluster_data(\"test_experiment/\"+model_name, subsample=True, frac=0.1, save_dir=\"aggregated/sub-0.1\", cluster=True)\n",
    "\n",
    "def test_cluster_subset():\n",
    "    model_name = id_generator(size=6)\n",
    "    #model_name = 'VZRH8X'\n",
    "    cluster(model_name)\n",
    "\n",
    "    test_cl = Cluster.from_cluster_data_dir(\"test_experiment/\"+model_name+\"/aggregated/sub-0.1\")\n",
    "    reference_cl = Cluster.from_cluster_data_dir(\"reference_experiment/cVAE/aggregated/sub-0.1\")\n",
    "\n",
    "    comp = test_cl.cluster_mpp.compare(reference_cl.cluster_mpp)[1]\n",
    "    assert comp['x']\n",
    "    assert comp['y']\n",
    "    assert comp['obj_ids']\n",
    "    assert comp['mpp']\n",
    "\n",
    "    import numpy as np\n",
    "    print(test_cl.cluster_mpp.data('latent'))\n",
    "    print(reference_cl.cluster_mpp.data('latent'))\n",
    "    # TODO why is latent not similar?\n",
    "    print(np.isclose(test_cl.cluster_mpp.data('latent'), reference_cl.cluster_mpp.data('latent')))\n",
    "\n",
    "    assert test_cl.cluster_annotation is not None\n",
    "    test_cl.cluster_mpp.get_adata(X='mpp', obs=['clustering'], obsm={\"X_latent\": \"latent\", \"X_umap\": \"umap\"})\n",
    "\n",
    "test_cluster_subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "from campa.data import MPPData\n",
    "import numpy as np\n",
    "\n",
    "def test_predict_full_data():\n",
    "    model_name = id_generator(size=6)\n",
    "    prepare_test_experiment(model_name, cluster_subset=True, full_data_prediction=False, full_data_clustering=False)\n",
    "\n",
    "    # predict full data\n",
    "    prepare_full_dataset(\"test_experiment/\"+model_name, save_dir=\"aggregated/full_data\")\n",
    "\n",
    "    # check results\n",
    "    for data_dir in [\"184A1_unperturbed/I09\", \"184A1_meayamycin/I12\"]:\n",
    "        # load mpp_data with cluster_rep\n",
    "        test_mpp_data = MPPData.from_data_dir(\n",
    "            data_dir,\n",
    "            base_dir=os.path.join(EXPERIMENT_DIR, \"test_experiment\", model_name, \"aggregated/full_data\"),\n",
    "            keys=[\"x\", \"y\", \"obj_ids\", \"latent\"],\n",
    "            data_config=\"TestData\",\n",
    "        )\n",
    "        reference_mpp_data = MPPData.from_data_dir(\n",
    "            data_dir,\n",
    "            base_dir=os.path.join(EXPERIMENT_DIR, \"test_experiment\", model_name, \"aggregated/full_data\"),\n",
    "            keys=[\"x\", \"y\", \"obj_ids\", \"latent\"],\n",
    "            data_config=\"TestData\",\n",
    "        )\n",
    "\n",
    "        comp = test_mpp_data.compare(reference_mpp_data)[1]\n",
    "        assert comp['x']\n",
    "        assert comp['y']\n",
    "        assert comp['obj_ids']\n",
    "        assert comp['mpp']\n",
    "        assert (np.isclose(test_mpp_data.data('latent'), reference_mpp_data.data('latent')).all())\n",
    "        #print(test_mpp_data.data('latent'))\n",
    "        #print(reference_mpp_data.data('latent'))\n",
    "\n",
    "test_predict_full_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot read with memmap:  /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments/reference_experiment/cVAE/aggregated/sub-0.1/clustering.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving partial keys of mpp data without a base_data_dir to enable correct loading\n",
      "Saving partial keys of mpp data without a base_data_dir to enable correct loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot read with memmap:  /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments/test_experiment/C3PW86/aggregated/full_data/184A1_unperturbed/I09/clustering.npy\n",
      "Cannot read with memmap:  /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments/test_experiment/C3PW86/aggregated/full_data/184A1_unperturbed/I09/clustering.npy\n",
      "{'x': True, 'y': True, 'obj_ids': True, 'labels': True, 'mpp': True, 'clustering': True, 'latent': True, 'channels': True, 'metadata': True}\n",
      "Cannot read with memmap:  /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments/test_experiment/C3PW86/aggregated/full_data/184A1_meayamycin/I12/clustering.npy\n",
      "Cannot read with memmap:  /Users/hannah.spitzer/projects/pelkmans/software_new/campa/tests/_experiments/test_experiment/C3PW86/aggregated/full_data/184A1_meayamycin/I12/clustering.npy\n",
      "{'x': True, 'y': True, 'obj_ids': True, 'labels': True, 'mpp': True, 'clustering': True, 'latent': True, 'channels': True, 'metadata': True}\n"
     ]
    }
   ],
   "source": [
    "def test_cluster_full_data():\n",
    "    model_name = id_generator(size=6)\n",
    "    prepare_test_experiment(model_name, cluster_subset=True, full_data_prediction=True, full_data_clustering=False)\n",
    "\n",
    "    # predict full data\n",
    "    project_cluster_data(\n",
    "        \"test_experiment/\"+model_name,\n",
    "        cluster_data_dir=\"aggregated/sub-0.1\",\n",
    "        cluster_name=\"clustering\",\n",
    "        save_dir=\"aggregated/full_data\",\n",
    "    )\n",
    "\n",
    "    # check results\n",
    "    for data_dir in [\"184A1_unperturbed/I09\", \"184A1_meayamycin/I12\"]:\n",
    "        # load mpp_data with cluster_rep\n",
    "        test_mpp_data = MPPData.from_data_dir(\n",
    "            data_dir,\n",
    "            base_dir=os.path.join(EXPERIMENT_DIR, \"test_experiment\", model_name, \"aggregated/full_data\"),\n",
    "            keys=[\"x\", \"y\", \"obj_ids\", \"clustering\"],\n",
    "            data_config=\"TestData\",\n",
    "        )\n",
    "        reference_mpp_data = MPPData.from_data_dir(\n",
    "            data_dir,\n",
    "            base_dir=os.path.join(EXPERIMENT_DIR, \"test_experiment\", model_name, \"aggregated/full_data\"),\n",
    "            keys=[\"x\", \"y\", \"obj_ids\", \"clustering\"],\n",
    "            data_config=\"TestData\",\n",
    "        )\n",
    "\n",
    "        assert test_mpp_data.compare(reference_mpp_data)[0]\n",
    "        \n",
    "\n",
    "test_cluster_full_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_extract_features():\n",
    "    pass\n",
    "    #TODO test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'x': True,\n",
       "  'y': True,\n",
       "  'obj_ids': True,\n",
       "  'mpp': True,\n",
       "  'labels': True,\n",
       "  'conditions': True,\n",
       "  'channels': True,\n",
       "  'metadata': True})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.data['train'].compare(reference_ds.data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mmpp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'MPPData'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m      ~/projects/pelkmans/software_new/campa/campa/data/_data.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "mpp_data.compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "874fcd6fbbd7997a0a341ba640ecd60060d2386464aa26f9f0c67495deab65ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('campa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
